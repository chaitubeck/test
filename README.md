Here is the fully updated Confluence-ready page, now including the additional long-term fix:
making Chat a separate microservice (instead of mixing it inside the main BFF).

This is written cleanly and professionally so you can paste it straight into Confluence.

â¸»

ðŸ”§ Router/Proxy Latency & Chat Load Stabilization Plan

1. Overview

We are experiencing intermittent latency spikes and 499 errors during periods of elevated chat traffic. Key drivers include rapid chat polling, long-lived connections, slow upstream responses, long API Gateway timeouts, and multi-hop routing (Router â†’ Proxy â†’ BFF).

The following Immediate, Short-Term, and Long-Term actions will fully stabilize the system and create a scalable foundation.

â¸»

2. Immediate Fix (Apply Today)

2.1 Increase Chat Polling Interval
	â€¢	Increase chat polling from 3 seconds â†’ 6 seconds.
	â€¢	Instantly reduces chat traffic by ~50%.
	â€¢	Helps router, proxy, and BFF maintain healthy connection pools.
	â€¢	Prevents overlapping in-flight chat polls.

This is the only change required for immediate relief without infra or code deployments.

â¸»

3. Short-Term Fixes (This Sprint)

Target: Prevent socket buildup, shorten stuck connections, and stabilize Router/Proxy under high chat volume.

â¸»

3.1 Reduce NGINX Router & Proxy Timeouts

Recommended:

keepalive_timeout 5s;
proxy_connect_timeout 3s;
proxy_read_timeout 8s;
proxy_send_timeout 8s;

Avoids long-running connections that hog resources during chat delays.

â¸»

3.2 Apply Chat-Specific Tight Timeout Overrides

location /frontendservice/.../onlineChat/ {
    proxy_read_timeout 4s;
    proxy_connect_timeout 2s;
}

Prevents slow chat endpoints from degrading the rest of the system.

â¸»

3.3 Add DNS Resolver Stability (for OpenShift)

resolver dns-default.openshift-dns valid=10s ipv6=off;
resolver_timeout 2s;

Mitigates stale IP issues and DNS resolution delays introduced by recent OpenShift upgrades.

â¸»

3.4 Adjust Router/Proxy Horizontal Scaling
	â€¢	Maintain 8â€“12 Router pods for headroom.
	â€¢	Increase Proxy pods if CPU or connection count spikes.
	â€¢	Validate HPA sensitivity for latency and RPS.

â¸»

3.5 Reduce API Gateway Timeouts (NEW)

Current timeout: 5 minutes â†’ too long for polling endpoints.

Recommended:
	â€¢	Reduce to 30 seconds or 1 minute.

Benefits:
	â€¢	Frees sockets sooner.
	â€¢	Reduces cascading delays.
	â€¢	Prevents queue pile-ups during chat degradation.

Alignment between Router/Proxy vs Gateway timeouts significantly reduces CLOSE_WAIT accumulation.

â¸»

4. Long-Term Fixes (Architecture)

Target: Remove systemic bottlenecks, decouple chat logic, and improve scalability.

â¸»

4.1 Redesign Chat Through BFF (UI â†’ Stateless)

UI should not manage Genesys session/chat IDs.

New model:
	â€¢	BFF creates and owns Genesys session IDs.
	â€¢	UI sends only:
	â€¢	user identifier
	â€¢	widget identifier
	â€¢	message text

Benefits:
	â€¢	Eliminates reconnect issues.
	â€¢	Reduces UI traffic.
	â€¢	Improves security.
	â€¢	Enables WebSockets/SSE future adoption.

â¸»

4.2 Make Chat a Dedicated Microservice (NEW)

Today chat logic lives inside the BFF alongside many unrelated features.
This creates tight coupling and forces the entire BFF to scale with chat load.

Recommendation:

Extract chat logic (Genesys integration, polling orchestration, session management) into a standalone microservice.

Benefits:
	â€¢	Isolates the most high-volume component.
	â€¢	Allows independent scaling during chat spikes.
	â€¢	Reduces load on the main BFF.
	â€¢	Cleaner separation of concerns (chat vs clinical/prescription features).
	â€¢	Enables specialized caching, retry patterns, session stores for chat only.

This microservice becomes:

UI â†’ Router â†’ Chat-Service â†’ Genesys Cloud
                          â†³ Chat-Session Cache (Redis)

The existing BFF becomes lighter and faster since chat is no longer interleaved with every patient/prescriber call.

â¸»

4.3 Remove Proxy Layer (Router â†’ BFF Direct)

Current:
Router â†’ Proxy â†’ BFF

Future:
Router â†’ BFF (direct)

Benefits:
	â€¢	Eliminates an entire hop.
	â€¢	Removes redundant timeouts and connection pools.
	â€¢	Simplifies routing and DNS.
	â€¢	Less failure propagation.
	â€¢	Substantial latency reduction.

â¸»

5. Summary

Immediate
	â€¢	Increase chat polling interval to 6 seconds.

Short-Term
	â€¢	Reduce NGINX router/proxy timeouts.
	â€¢	Add chat-specific timeout overrides.
	â€¢	Add DNS resolver stability.
	â€¢	Tune Router/Proxy scaling.
	â€¢	Reduce API Gateway timeouts to 30â€“60s.

Long-Term
	â€¢	Move chat session handling to BFF (UI stateless).
	â€¢	Create a dedicated Chat Microservice.
	â€¢	Remove the proxy layer (direct Router â†’ BFF).

â¸»

6. Next Steps

Item	Owner	Target Date
Increase chat polling interval to 6s	UI Team	Immediate
Update router/proxy timeouts	Platform	This sprint
Add resolver + chat-specific timeouts	Platform	This sprint
Reduce Gateway timeout from 5m â†’ 30â€“60s	API Gateway Team	This sprint
Review Router/Proxy scaling thresholds	DevOps	This sprint
Redesign chat in BFF (UI stateless)	BFF Team	Q1
Create dedicated Chat Microservice	BFF + Architecture	Q1â€“Q2
Remove proxy layer	Platform + BFF	Q1â€“Q2


â¸»

If you want, I can also generate:
	â€¢	A visual architecture diagram showing current vs target
	â€¢	A slide deck for leadership
	â€¢	Or a risk matrix explaining what happens if we donâ€™t implement these changes

Just tell me.
